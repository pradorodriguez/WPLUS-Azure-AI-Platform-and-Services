{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DPO Fine-Tuning GPT-4-o Model for Text Q&A - A Python SDK Experience\n",
    "\n",
    "Learn how to fine-tune the **gpt-4-o** model using Direct Preference Optimization (DPO) with Python SDK. \n",
    "\n",
    "You can either run this notebook locally or run on an **AML CPU Compute Standard_D13_v2** with Kernel type **Python 3.10 - SDK v2**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Prerequisites\n",
    "\n",
    "* An Azure subscription.\n",
    "* A [Microsoft Foundry project](https://learn.microsoft.com/en-us/azure/ai-foundry/how-to/create-projects) in Azure AI Foundry portal.\n",
    "    * Fine-tuning access requires **Cognitive Services OpenAI Contributor** in the Microsoft Foundry resource.\n",
    "    * A Microsoft Foundry resource created in a supported fine-tuning region (e.g. East US 2 or Sweden Central).\n",
    "    * A model deployment of **gpt-4o** base model, named **gpt-4o**.  \n",
    "* A Training and Validation datasets:\n",
    "  * at least 10 high-quality samples are required.\n",
    "  * must be formatted in the JSON Lines (JSONL) document with UTF-8 encoding.\n",
    "* Python version at least: **3.10**\n",
    "* The OpenAI Python library version for this test notebook: **1.58.1**\n",
    "* [Jupyter Notebooks](https://jupyter.org/) or **Visual Studio Code** with the **Jupyter** notebook extension installed.\n",
    "* An `.env` file to store Azure credentials as environmental variables. **Be sure not to share this file with others or upload it to a public GitHub repository.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 1: Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Retrieve resources values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Go to your Microsoft Foundry resource in the Azure portal\n",
    "1. In the **Overview** section, copy and save the following values:\n",
    "    * Microsoft Foundry Resource Name\n",
    "    * Resource group\n",
    "    * Subscription ID\n",
    "\n",
    "    <img src=\"images/screenshot-foundry-overview.png\" alt=\"Screenshot of the Azure OpenAI resource management pane.\" width=\"800\"/>\n",
    "1. Go to **Resource Management**, click **Keys and Endpoint** sub-section\n",
    "1. Click **OpenAI**\n",
    "1. Copy and save the following values:\n",
    "    * **KEY 1**\n",
    "    * **Endpoint URL**.\n",
    "        * Select one of these endpoint links: **Language APIs**, **Dall-e APIs** or **Whisper APIs**\n",
    "\n",
    "    <img src=\"images/screenshot-foundry-keys-and-endpoint.png\" alt=\"Screenshot of the Azure OpenAI resource management pane.\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add credentials and variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "1. Rename the [.env.example](../../.env.example) to \"**.env**\".\n",
    "1. Open the [.env](../../.env) file located in the root.\n",
    "/\" folder.\n",
    "1. Paste saved values to the variables in the file **azure.env**:\n",
    "    * AZURE_OPENAI_ENDPOINT = \"_<Foundry_Endpoint_URL>_\"\n",
    "    * AZURE_OPENAI_API_KEY = \"_<Foundry_KEY_1>_\"\n",
    "    * AZURE_SUBSCRIPTION_ID = \"_<Foundry_Subscription_ID>_\"\n",
    "    * AZURE_PROJECT_NAME = \"_<Foundry_Name>_\"\n",
    "    * AZURE_RESOURCE_GROUP = \"_<Foundry_ResourceGroup_Name>_\"\n",
    "1. Save the file and close it. \n",
    "\n",
    "> **Note:** **Do not** distribute this file as this contains credential information! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Authentication Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running the next cell, make sure you're authenticated with Azure CLI. \n",
    "\n",
    "* Open a terminal inside VSC.\n",
    "    * Run the following command in your terminal:\n",
    "\n",
    "```\n",
    "az login --use-device-code\n",
    "```\n",
    "\n",
    "* This will provide you with a device code and URL to authenticate in your browser to Azure.\n",
    "    * Authenticate using the skillable Azure Username and TAP(Temporary Access Pass).\n",
    "* Go back to the terminal and select the default subscription.\n",
    "\n",
    "The Device Token will be used in this lab for:\n",
    "\n",
    "* Remote development environments\n",
    "* Systems without a default browser\n",
    "* Corporate environments with strict security policies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Jupyter Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inside this jupyter notebook within VSC, select the **Python Kernel**:\n",
    "\n",
    "* Python 3.12.10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install required Python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q \"matplotlib==3.10.8\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import required Python libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import json\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "from io import BytesIO, StringIO\n",
    "from azure.identity import DefaultAzureCredential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load environmental variables to assign credentials "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load env. file\n",
    "load_dotenv(dotenv_path=\"../../.env\")\n",
    "\n",
    "# Assign Azure resources  \n",
    "subscription_id = os.getenv(\"AZURE_SUBSCRIPTION_ID\") # name of the Azure Subscription ID\n",
    "resource_name = os.getenv(\"AZURE_PROJECT_NAME\") # name of the Foundry resource\n",
    "rg_name = os.getenv(\"AZURE_RESOURCE_GROUP\") # name of the resource group\n",
    "\n",
    "\n",
    "# Assign Foundry credentials \n",
    "client = AzureOpenAI(\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    api_version=\"2025-02-01-preview\", # This API version or later is required for DPO fine-tuning.\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    ")\n",
    "\n",
    "print(\"Azure OpenAI client data loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Reads and displays the first few lines from a .jsonl (JSON Lines) file\n",
    "def read_jsonl(file_path, top_lines=5):\n",
    "    \"\"\"Reads and displays the first few lines from a .jsonl (JSON Lines) file.\"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        messages = [line for line in f]\n",
    "        for mes in messages[:top_lines]:\n",
    "            print(mes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot fine-tuning metrics including loss and accuracy for training and validation\n",
    "def show_ft_metrics(results_df, window_size=5):\n",
    "    \"\"\"Plot fine-tuning metrics including loss and accuracy for training and validation.\"\"\"\n",
    "    # Convert timestamp column to datetime if it exists\n",
    "    if 'timestamp' in results_df.columns:\n",
    "        results_df['timestamp'] = pd.to_datetime(results_df['timestamp'])\n",
    "    \n",
    "    # Drop rows where valid_loss is NaN or valid_loss is -1.0\n",
    "    filtered_df = results_df.dropna(subset=['valid_loss'])\n",
    "    filtered_df = filtered_df.loc[filtered_df['valid_loss'] != -1.0]\n",
    "    \n",
    "    # Compute rolling means (only on numeric columns)\n",
    "    results_df_smooth = results_df.select_dtypes(include=['number']).rolling(window=window_size).mean()\n",
    "    filtered_df_smooth = filtered_df.select_dtypes(include=['number']).rolling(window=window_size).mean()\n",
    "    \n",
    "    # Plot the curves\n",
    "    plt.figure(figsize=(16, 6))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(results_df_smooth['step'], results_df_smooth['train_loss'],  color='blue')\n",
    "    plt.title('Train Loss')\n",
    "    plt.xlabel('Step')\n",
    "    plt.ylabel('Loss')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(filtered_df_smooth['step'], filtered_df_smooth['valid_loss'], color='red')\n",
    "    plt.title('Validation Loss')\n",
    "    plt.xlabel('Step')\n",
    "    plt.ylabel('Loss')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a pandas DataFrame from a dictionary and sort it by a 'created' or 'created_at' timestamp column for displaying OpenAI API tables\n",
    "def date_sorted_df(details_dict):\n",
    "    \"\"\"Create a pandas DataFrame from a dictionary and sort it by a 'created' or 'created_at' timestamp column for displaying OpenAI API tables.\"\"\"\n",
    "    df = pd.DataFrame(details_dict)\n",
    "    \n",
    "    if 'created' in df.columns:\n",
    "        df.rename(columns={'created': 'created_at'}, inplace=True)\n",
    "    \n",
    "    # Convert 'created_at' from Unix timestamp to human-readable date/time format\n",
    "    df['created_at'] = pd.to_datetime(df['created_at'], unit='s').dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    if 'finished_at' in df.columns:\n",
    "        # Convert 'finished_at' from Unix timestamp to human-readable date/time format, keeping null values as is\n",
    "        df['finished_at'] = pd.to_datetime(df['finished_at'], unit='s', errors='coerce').dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "    # Sort DataFrame by 'created_at' in descending order\n",
    "    df = df.sort_values(by='created_at', ascending=False)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 2: Prepare Training & Validation Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fine-tune a base model like GPT-4o using Direct Preference Optimization (DPO), we need a dataset in which each sample includes:\n",
    "\n",
    "- **User Prompt**: A natural user message or question that initiates the assistant's response.\n",
    "- **Preferred Output**: An ideal, high-quality assistant response aligned with a specific tone or style (e.g., optimistic).\n",
    "- **Non-Preferred Output**: A less desirable response, often with contrasting tone or reasoning (e.g., pessimistic)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Dataset Output Format (JSONL, One Line Per Sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the format example for each sample of the dataset. These will be saved as .jsonl files for DPO fine-tuning on Azure:\n",
    "\n",
    "```json\n",
    "{\"input\": {\"messages\": [{\"role\": \"user\", \"content\": \"...\"}]}, \"preferred_output\": [{\"role\": \"assistant\", \"content\": \"...\"}], \"non_preferred_output\": [{\"role\": \"assistant\", \"content\": \"...\"}]}\n",
    "{\"input\": {\"messages\": [{\"role\": \"user\", \"content\": \"...\"}]}, \"preferred_output\": [{\"role\": \"assistant\", \"content\": \"...\"}], \"non_preferred_output\": [{\"role\": \"assistant\", \"content\": \"...\"}]}\n",
    "{\"input\": {\"messages\": [{\"role\": \"user\", \"content\": \"...\"}]}, \"preferred_output\": [{\"role\": \"assistant\", \"content\": \"...\"}], \"non_preferred_output\": [{\"role\": \"assistant\", \"content\": \"...\"}]}\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "> **Note:** For demonstration purposes, weâ€™ve pre-generated 10 training samples and 10 validation samples to help you save on compute costs and training time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Do initial data checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check some data samples \n",
    "training_file_path = \"./data/gpt4o_generated_qa_dpo_train_10_samples.jsonl\"\n",
    "validation_file_path = \"./data/gpt4o_generated_qa_dpo_validation_10_samples.jsonl\" \n",
    "\n",
    "read_jsonl(training_file_path, top_lines=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 3: Upload Datasets for Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload training file\n",
    "training_response = client.files.create(\n",
    "    file = open(training_file_path, \"rb\"), purpose=\"fine-tune\")\n",
    "\n",
    "training_file_id = training_response.id\n",
    "\n",
    "# Upload validation file\n",
    "validation_response = client.files.create(\n",
    "    file = open(validation_file_path, \"rb\"), purpose=\"fine-tune\")\n",
    "\n",
    "validation_file_id = validation_response.id\n",
    "\n",
    "print(\"Training file ID:\", training_file_id)\n",
    "print(\"Validation file ID:\", validation_file_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Configure and Start Fine-Tuning Job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is some guidance if you want to adjust the hyperparameters of the fine-tuning process. \n",
    "\n",
    "> **Note:** We configured these parameters to reduce resource consumption and accelerate the fine-tuning process. \n",
    "\n",
    "| Hyperparameter | Description |\n",
    "|-----------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| `Beta` | \"auto\" or number, is a new option that is only available for DPO. It's a floating point number between 0 and 2 that controls how strictly the new model will adhere to its previous behavior, versus aligning with the provided preferences. A high number will be more conservative (favoring previous behavior), and a lower number will be more aggressive (favor the newly provided preferences more often). |\n",
    "| `Batch size` | The batch size to use for training. When set to default, batch_size is calculated as 0.2% of examples in training set and the max is 256. |\n",
    "| `Learning rate multiplier` | The fine-tuning learning rate is the original learning rate used for pre-training multiplied by this multiplier. We recommend experimenting with values between 0.5 and 2. Empirically, we've found that larger learning rates often perform better with larger batch sizes. Must be between 0.0 and 5.0. |\n",
    "| `Number of epochs` | Number of training epochs. An epoch refers to one full cycle through the data set. If set to default, number of epochs will be determined dynamically based on the input data. |\n",
    "| `Seed` | The seed controls the reproducibility of the job. Passing in the same seed and job parameters should produce the same results, but may differ in rare cases. If a seed is not specified, one will be generated for you. |\n",
    "\n",
    "> **Note:** The Fine Tuning Job might take some time to complete. Time may varied from 30 minutes to 50 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit fine-tuning training job\n",
    "project_name = \"gpt4_o_dpo_ft\"\n",
    "\n",
    "ft_job = client.fine_tuning.jobs.create(\n",
    "    suffix=project_name,\n",
    "    training_file = training_file_id,\n",
    "    validation_file = validation_file_id,\n",
    "    model=\"gpt-4o-2024-08-06\", # baseline model name (not the deployment name)\n",
    "    method={\n",
    "        \"type\": \"dpo\",\n",
    "        \"dpo\": {\n",
    "            \"hyperparameters\": {\n",
    "                \"beta\": 1.0,\n",
    "                \"batch_size\": 32,\n",
    "                \"learning_rate_multiplier\": 5.0,\n",
    "                \"n_epochs\": 1\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "    seed=3 # seed parameter controls reproducibility of the fine-tuning job. If no seed is specified one will be generated automatically.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Track Fine-Tuning Job Status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Track the training job status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check the fine-tuning job status\n",
    "client.fine_tuning.jobs.list(limit=1).to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List fine-tuning events\n",
    "\n",
    "\n",
    "> **Note:** API version: 2024-05-01-preview or later is required for this command.\n",
    "\n",
    "This step is helpful to examine the individual fine-tuning events that were generated during training. in this example it is used to retrieve the fine tuninig job id of this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# List 5 recent fine-tuning jobs\n",
    "ft_jobs = client.fine_tuning.jobs.list(limit=5).to_dict()\n",
    "jobs_df = date_sorted_df(pd.DataFrame(ft_jobs[\"data\"]))\n",
    "jobs_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the latest fine-tuning job ID\n",
    "latest_ft_job_id = jobs_df.iloc[0][\"id\"]\n",
    "latest_ft_job_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:** \n",
    ">\n",
    "> The following snipet must be executed ONLY after the fine tuning job has been **Completed**.\n",
    ">\n",
    "> Else and error message will be received."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Retrieve the name of your newly DPO fine-tuned model\n",
    "ft_job = client.fine_tuning.jobs.retrieve(latest_ft_job_id) # Latest FT job will be retrieved. To use another Job ID, replace \"latest_ft_job_id\" with the actual job-id in your list\n",
    "fine_tuned_model = ft_job.to_dict()['fine_tuned_model']\n",
    "fine_tuned_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieve fine-tuning metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Retrieve fine-tuning metrics from result file\n",
    "result_file_id = ft_job.to_dict()['result_files'][0]\n",
    "results_content = client.files.content(result_file_id).content.decode()\n",
    "\n",
    "data_io = StringIO(results_content)\n",
    "results_df = pd.read_csv(data_io)\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot train and validation metrics\n",
    "show_ft_metrics(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Deploy the Fine-Tuned Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:** \n",
    ">\n",
    "> Only one deployment is permitted for a customized model. An error occurs if you select an already-deployed customized model.\n",
    ">\n",
    "> The deployment process may take 10 to 20 mins.\n",
    "\n",
    "The code below shows how to deploy the model using the Control Plane API. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Deploy the fine-tuned model as an Azure Managed Online Endpoint\n",
    "# fine_tuned_model = MS Foundry deployment name\n",
    "\n",
    "credential = DefaultAzureCredential()\n",
    "token = credential.get_token(\"https://management.azure.com/.default\").token\n",
    "\n",
    "deploy_params = {'api-version': \"2023-05-01\"} \n",
    "deploy_headers = {'Authorization': 'Bearer {}'.format(token), 'Content-Type': 'application/json'}\n",
    "\n",
    "deploy_data = {\n",
    "    \"sku\": {\"name\": \"standard\", \"capacity\": 50}, \n",
    "    \"properties\": {\n",
    "        \"model\": {\n",
    "            \"format\": \"OpenAI\",\n",
    "            \"name\": fine_tuned_model, # retrieve this value from the previous calls, it will look like gpt-4o-2024-08-06.ft-b044a9d3cf9c4228b5d393567f693b83\n",
    "            \"version\": \"1\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "deploy_data = json.dumps(deploy_data)\n",
    "\n",
    "request_url = f'https://management.azure.com/subscriptions/{subscription_id}/resourceGroups/{rg_name}/providers/Microsoft.CognitiveServices/accounts/{resource_name}/deployments/{project_name}'\n",
    "\n",
    "print('Creating a new deployment...')\n",
    "\n",
    "r = requests.put(request_url, params=deploy_params, headers=deploy_headers, data=deploy_data)\n",
    "\n",
    "print(r)\n",
    "print(r.reason)\n",
    "print(r.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 7: Test the Deployed Fine-Tuned Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After your fine-tuned model is deployed, you can use it like any other deployed model in either the [Chat Playground in Azure AI Foundry](https://ai.azure.com/), or via the chat completion API. \n",
    "\n",
    "For example, you can send a chat completion call to your deployed model, as shown in the following Python code snippet. \n",
    "\n",
    "> **Note:** \n",
    ">\n",
    "> The following snipet must be executed ONLY after the fine tuning model has been **Deployed**.\n",
    ">\n",
    "> Else and error message will be received."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check output from the deployed DPO fine-tuned model via Foundry API\n",
    "test_messages = [\n",
    "    {'role': 'system', 'content': 'You are a helpful assistant.'},\n",
    "    {'role': 'user', 'content': 'Will AI improve the logistics of renewable energy?'}\n",
    "]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=project_name, \n",
    "    messages=test_messages, \n",
    "    temperature=0.7,\n",
    "    max_tokens=800)\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Evaluate the Base GPT-4o and the DPO Fine-Tuned GPT-4o Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To keep the demo lightweight, cost-effective and within an acceptable timeframe, we previously used both the Base GPT-4o model and the DPO Fine-Tuned GPT-4o model to answer a pre-selected set of 49 test questions. The table below presents the detailed results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "comparison_df = pd.read_csv(\"./data/test_qa_pairs_base_gpt_4o_versus_dpo_fine_tuned_gpt_4o.csv\")\n",
    "comparison_df.info()\n",
    "comparison_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row represents a test case, and the columns are defined as follows:\n",
    "\n",
    "- **question**: The original user prompt or test question.\n",
    "- **gpt_4o_base_answer**: The response generated by the Base GPT-4o model.\n",
    "- **gpt_4o_base_answer_label**: An automatically assigned label (e.g., Positive, Neutral, Negative) by the Base GPT-4o model.\n",
    "- **gpt_4o_base_answer_explanation**: A brief explanation justifying the assigned label by the Base GPT-4o model.\n",
    "- **gpt_4o_dpo_fine_tuned_answer**: The response generated by the DPO Fine-Tuned GPT-4o model.\n",
    "- **gpt_4o_dpo_fine_tuned_answer_label**: An automatically assigned label (e.g., Positive, Neutral, Negative) by the Base GPT-4o model.\n",
    "- **gpt_4o_dpo_fine_tuned_answer_explanation**: A brief explanation justifying the assigned label by the Base GPT-4o model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assuming df is your DataFrame\n",
    "base_label_counts = comparison_df['gpt_4o_base_answer_label'].value_counts().sort_index()\n",
    "dpo_label_counts = comparison_df['gpt_4o_dpo_fine_tuned_answer_label'].value_counts().sort_index()\n",
    "\n",
    "# Combine into a single DataFrame\n",
    "label_comparison_df = pd.DataFrame({\n",
    "    'Base GPT-4o': base_label_counts,\n",
    "    'DPO Fine-Tuned GPT-4o': dpo_label_counts\n",
    "}).fillna(0).astype(int)\n",
    "\n",
    "# Display table\n",
    "display(label_comparison_df)\n",
    "\n",
    "# Plot grouped bar chart\n",
    "label_comparison_df.plot(\n",
    "    kind='bar',\n",
    "    figsize=(8, 5),\n",
    "    color=['#1f77b4', '#2ca02c'],\n",
    "    edgecolor='black'\n",
    ")\n",
    "\n",
    "plt.title('Answer Label Distribution: Base vs. DPO Fine-Tuned GPT-4o')\n",
    "plt.xlabel('Answer Label')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=0)\n",
    "plt.legend(title='Model')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the label distribution table and the bar chart, we observe a clear shift in tone: the DPO fine-tuned GPT-4o model consistently produces more positive responses compared to the base model. This suggests that the fine-tuning process successfully aligned the model toward a more optimistic attitude when answering philosophical and forward-thinking questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 9: Delete the Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is **strongly recommended** that once you're done with this tutorial and have tested a few chat completion calls against your fine-tuned model, that you delete the model deployment, since the fine-tuned / customized models have an [hourly hosting cost](https://azure.microsoft.com/zh-cn/pricing/details/cognitive-services/openai-service/#pricing) associated with them once they are deployed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
